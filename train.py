import torch
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm
import os
from model import BiCrack
from loss import BiCrackLoss
from dataset import CrackDataset


# è®¡ç®—è¯„ä»·æŒ‡æ ‡
def calculate_metrics(preds, targets):
    preds = (torch.sigmoid(preds) > 0.5).float()
    tp = (preds * targets).sum().item()
    fp = (preds * (1 - targets)).sum().item()
    fn = ((1 - preds) * targets).sum().item()
    precision = tp / (tp + fp + 1e-8)
    recall = tp / (tp + fn + 1e-8)
    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)
    return precision, recall, f1


def main():
    # ================= 1. åŸºç¡€è®¾ç½® =================
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"å½“å‰ä½¿ç”¨è®¾å¤‡: {device}")

    EPOCHS = 150
    BATCH_SIZE = 8
    LR = 0.0001
    image_dir = "dataset/images"
    mask_dir = "dataset/masks"

    if not os.path.exists(image_dir) or len(os.listdir(image_dir)) == 0:
        print("é”™è¯¯ï¼šè¯·æ£€æŸ¥ dataset/images æ–‡ä»¶å¤¹æ˜¯å¦ä¸ºç©ºï¼")
        return

    # ================= 2. åŠ è½½æ•°æ®é›† =================
    print("æ­£åœ¨åŠ è½½æ•°æ®é›†...")
    full_dataset = CrackDataset(image_dir, mask_dir)
    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)
    print(f"æ€»å›¾ç‰‡æ•°: {len(full_dataset)} | è®­ç»ƒé›†: {train_size} | æµ‹è¯•é›†: {val_size}")

    # ================= 3. åˆå§‹åŒ–æ¨¡å‹ä¸ä¼˜åŒ–å™¨ =================
    model = BiCrack(num_classes=1).to(device)
    criterion = BiCrackLoss(w_bce=0.5, w_dice=0.5).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
    scaler = torch.cuda.amp.GradScaler()

    best_f1 = 0.0
    save_dir = "weights"
    os.makedirs(save_dir, exist_ok=True)  # åˆ›å»ºä¿å­˜æƒé‡çš„æ–‡ä»¶å¤¹

    # ================= 4. å¼€å§‹è®­ç»ƒå¾ªç¯ =================
    for epoch in range(EPOCHS):
        print(f"\nEpoch [{epoch + 1}/{EPOCHS}]")

        # --- è®­ç»ƒé˜¶æ®µ ---
        model.train()
        train_loss = 0.0
        pbar = tqdm(train_loader, desc="Training")

        for images, masks in pbar:
            images = images.to(device)
            masks = masks.to(device)
            optimizer.zero_grad()

            with torch.cuda.amp.autocast():
                outputs = model(images)
                loss = criterion(outputs, masks)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            train_loss += loss.item()
            pbar.set_postfix({'loss': f"{loss.item():.4f}"})

        scheduler.step()
        avg_train_loss = train_loss / len(train_loader)

        # --- éªŒè¯é˜¶æ®µ ---
        model.eval()
        val_loss, val_precision, val_recall, val_f1 = 0, 0, 0, 0

        with torch.no_grad():
            for images, masks in tqdm(val_loader, desc="Validating"):
                images = images.to(device)
                masks = masks.to(device)

                outputs = model(images)
                loss = criterion(outputs, masks)
                val_loss += loss.item()

                p, r, f1 = calculate_metrics(outputs, masks)
                val_precision += p
                val_recall += r
                val_f1 += f1

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_val_loss = val_loss / len(val_loader)
        avg_p = val_precision / len(val_loader)
        avg_r = val_recall / len(val_loader)
        avg_f1 = val_f1 / len(val_loader)

        print(f"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}")
        print(f"Val Precision: {avg_p:.4f} | Val Recall: {avg_r:.4f} | Val F1: {avg_f1:.4f}")

        # ================= 5. ä¿å­˜æ¨¡å‹æƒé‡ =================
        # 5.1 ä¿å­˜å½“å‰epochçš„æƒé‡ï¼ˆæ–°å¢éƒ¨åˆ†ï¼‰
        current_save_path = os.path.join(save_dir, f"bicrack_epoch_{epoch + 1}.pth")
        torch.save(model.state_dict(), current_save_path)
        print(f"ğŸ’¾ å·²ä¿å­˜å½“å‰epochæ¨¡å‹è‡³ {current_save_path}")

        # 5.2 ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        if avg_f1 > best_f1:
            best_f1 = avg_f1
            best_save_path = os.path.join(save_dir, "bicrack_best.pth")
            torch.save(model.state_dict(), best_save_path)
            print(f"â­ å‘ç°æ›´å¥½çš„æ¨¡å‹ï¼å·²ä¿å­˜è‡³ {best_save_path} (F1: {best_f1:.4f})")


if __name__ == "__main__":
    main()